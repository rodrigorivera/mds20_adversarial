#Adversarial Attacks on Categorical SequenceClassiers: First Status Update Report

##**1  Introduction to adversarial attacks**

####Adversarial examples aim at causing target model to make a mistake on prediction.  It canbe either be intended or unintended to
cause a model to perform poorly. No matter it is anintentional or unintentional adversarial attack, evaluating adversarial examples 
has become atrend of building a robust deep learning model and understanding the shortcomings of models.First examples of adversarial
attacks came from computer vision field:  if we change somepixels in the tensor, that represents the picture, the model classies this
image wrongly butfrom human perspective not much changed. In NLP adversarial attacks are more various:
